{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fichier de test IA pour Jots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Librairies and models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/neuml/txtai\n",
    "\n",
    "https://huggingface.co/models?sort=downloads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wget\n",
    "import requests\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "from txtai.embeddings import Embeddings\n",
    "from txtai.pipeline import Summary\n",
    "from txtai.pipeline import Textractor\n",
    "from txtai.pipeline import Labels\n",
    "from txtai.pipeline import Translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Model of summary\"\"\"\n",
    "\n",
    "summary_model = Summary(\"sshleifer/distilbart-cnn-12-6\")\n",
    "summary_model2 = Summary(\"facebook/bart-large-cnn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Model of textractor\"\"\"\n",
    "\n",
    "textractor_model = Textractor()\n",
    "textractor_model_paragraph = Textractor(paragraphs=True)\n",
    "textractor_model_sentence = Textractor(sentences=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Model of embedding\"\"\"\n",
    "\n",
    "embeddings = Embeddings({\"path\": \"sentence-transformers/nli-mpnet-base-v2\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Model of label\"\"\"\n",
    "\n",
    "labels_model = Labels(\"facebook/bart-large-mnli\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Model of translate\"\"\"\n",
    "\n",
    "translate_model = Translation()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Text summarize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test du résumé de document\n",
    "\n",
    "\n",
    "with open('document2.txt', 'r', encoding=\"utf8\") as f:\n",
    "    document = f.read()\n",
    "\n",
    "summary_model(document)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Corelation between data and query\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query                Best Match\n",
      "--------------------------------------------------\n",
      "who enjoy brownie    Quentin like chocolate\n",
      "[(2, 0.432331919670105), (5, 0.22089824080467224), (4, 0.10008981823921204), (7, 0.08463199436664581), (1, 0.014545567333698273), (0, 0.01050751656293869), (6, 0.00588153675198555), (3, -0.046505413949489594)]\n"
     ]
    }
   ],
   "source": [
    "data = [\"In 2021, Mem is the fastest way to capture, connect, and make use of information. It is a universally accessible, universally available, search engine. It pulls relevant information to the tip of your fingers, lets you save anything for later later. Mem Spotlight, a feature that sits on the top of the knowledge graph, is a top feature.\",\n",
    "        \"Jots is an application at the crossing between note taking, journaling, time and task management. It is like the wikipedia of your life and projects with an assistant to help with organizing content and recalling what matters at the right moment. It gives structures to the content, it links everything together into a big graph.\",\n",
    "        \"Quentin like chocolate\",\n",
    "        \"Cedric went to theatre on thurday\",\n",
    "        \"Cedric like coding app\",\n",
    "        \"Gift idea for Mel: t-shirt, bag\",\n",
    "        \"List of crazy AI application\",\n",
    "        \"Cave exploration session with Emeric, Gaetan and Annabelle on 23/09/22 at Bryant.\"]\n",
    "\n",
    "\n",
    "print(\"%-20s %s\" % (\"Query\", \"Best Match\"))\n",
    "print(\"-\" * 50)\n",
    "\n",
    "query = \"who enjoy brownie\"\n",
    "# Get index of best section that best matches query\n",
    "uid = embeddings.similarity(query, data)[0][0]\n",
    "answers = embeddings.similarity(query, data)\n",
    "\n",
    "print(\"%-20s %s\" % (query, data[uid]))\n",
    "print(answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query                Best Match\n",
      "--------------------------------------------------\n",
      "feel good story      Maine man wins $1M from $25 lottery ticket\n",
      "climate change       Canada's last fully intact ice shelf has suddenly collapsed, forming a Manhattan-sized iceberg\n",
      "public health story  US tops 5 million confirmed virus cases\n",
      "war                  Beijing mobilises invasion craft along coast as Taiwan tensions escalate\n",
      "wildlife             The National Park Service warns against sacrificing slower friends in a bear attack\n",
      "asia                 Beijing mobilises invasion craft along coast as Taiwan tensions escalate\n",
      "lucky                Maine man wins $1M from $25 lottery ticket\n",
      "dishonest junk       Make huge profits without work, earn up to $100,000 a day\n"
     ]
    }
   ],
   "source": [
    "data = [\"US tops 5 million confirmed virus cases\",\n",
    "        \"Canada's last fully intact ice shelf has suddenly collapsed, forming a Manhattan-sized iceberg\",\n",
    "        \"Beijing mobilises invasion craft along coast as Taiwan tensions escalate\",\n",
    "        \"The National Park Service warns against sacrificing slower friends in a bear attack\",\n",
    "        \"Maine man wins $1M from $25 lottery ticket\",\n",
    "        \"Make huge profits without work, earn up to $100,000 a day\"]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"%-20s %s\" % (\"Query\", \"Best Match\"))\n",
    "print(\"-\" * 50)\n",
    "\n",
    "for query in (\"feel good story\", \"climate change\", \"public health story\", \"war\", \"wildlife\", \"asia\", \"lucky\", \"dishonest junk\"):\n",
    "    # Get index of best section that best matches query\n",
    "    uid = embeddings.similarity(query, data)[0][0]\n",
    "\n",
    "    print(\"%-20s %s\" % (query, data[uid]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query                Best Match\n",
      "--------------------------------------------------\n",
      "yellow               US tops 5 million confirmed virus cases\n",
      "tips                 Beijing mobilises invasion craft along coast as Taiwan tensions escalate\n",
      "public health story  US tops 5 million confirmed virus cases\n",
      "war                  Beijing mobilises invasion craft along coast as Taiwan tensions escalate\n",
      "wildlife             The National Park Service warns against sacrificing slower friends in a bear attack\n",
      "asia                 Beijing mobilises invasion craft along coast as Taiwan tensions escalate\n",
      "lucky                Maine man wins $1M from $25 lottery ticket\n",
      "dishonest junk       Make huge profits without work, earn up to $100,000 a day\n"
     ]
    }
   ],
   "source": [
    "# Create an index for the list of text\n",
    "embeddings.index([(uid, text, None) for uid, text in enumerate(data)])\n",
    "\n",
    "print(\"%-20s %s\" % (\"Query\", \"Best Match\"))\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Run an embeddings search for each query\n",
    "for query in (\"yellow\", \"tips\", \"public health story\", \"war\", \"wildlife\", \"asia\", \"lucky\", \"dishonest junk\"):\n",
    "    # Extract uid of first result\n",
    "    # search result format: (uid, score)\n",
    "    uid = embeddings.search(query, 1)[0][0]\n",
    "\n",
    "    # Print text\n",
    "    print(\"%-20s %s\" % (query, data[uid]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Text extractor and sumarize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Private equity still investing billions in dirty energy despite pledge to clean up. Carlyle, Warburg Pincus and KKR are the worst offenders according to a new scorecard of private equity climate risks. The eight firms manage a combined $3. 6tn in assets including $216bn in energy projects.'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#POC\n",
    "\n",
    "url = \"http://planetedata.windows8.free.fr/lightscribe_free_1418.htm\"\n",
    "\n",
    "article = wget.download(url)\n",
    "filename = \"file:///C:\\\\Users\\\\Qquentin\\\\Downloads\\\\\" + article\n",
    "\n",
    "text = textractor_model(\"file:///C:\\\\Users\\\\Qquentin\\\\Downloads\\\\\" + article)\n",
    "\n",
    "summary_model(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset url\n",
    "\n",
    "data_url = ['https://www.lemonde.fr/pixels/article/2022/09/14/concurrence-google-echoue-a-faire-annuler-une-amende-record-devant-la-justice-europeenne_6141575_4408996.html',\n",
    "'https://www.leparisien.fr/faits-divers/incendie-en-gironde-des-centaines-de-personnes-evacuees-pres-dun-millier-de-pompiers-mobilises-14-09-2022-XDWAUFYCPNDYHHMG4AR25ODRII.php',\n",
    "'https://reflect.app/',\n",
    "'https://apps.apple.com/us/app/reflect-guided-daily-journal/id1443541171',\n",
    "'https://www.assemblyai.com/?ref=ph_topic&utm_campaign=jun2022&utm_medium=cpc&utm_source=producthunt',\n",
    "'https://stackoverflow.com/questions/65808445/electron-how-to-create-deep-linking-on-linux',\n",
    "'https://heyday.xyz/',\n",
    "'https://github.com/alex-shapiro/ditto',\n",
    "'http://archagon.net/blog/2018/03/24/data-laced-with-history/',\n",
    "'https://towardsdatascience.com/milvus-pinecone-vespa-weaviate-vald-gsi-what-unites-these-buzz-words-and-what-makes-each-9c65a3bd0696',\n",
    "'https://www.tutorialspoint.com/python/file_close.htm',\n",
    "'https://www.theguardian.com/football/2022/sep/14/premier-league-to-honour-queen-with-silence-applause-and-national-anthem-managers-suits',\n",
    "'https://www.amazon.fr/GIANTARM-Filament-1-75mm-Imprimante-Transparent/dp/B08LZ7L7L1/?_encoding=UTF8&pd_rd_w=mk0pF&content-id=amzn1.sym.09646d5d-e648-4ed9-8271-617e79ecf41a&pf_rd_p=09646d5d-e648-4ed9-8271-617e79ecf41a&pf_rd_r=JHAND8X5AFF59JR900TP&pd_rd_wg=vBmkt&pd_rd_r=a18f73ce-0909-40bd-b6aa-2f04fb130f59&ref_=pd_gw_bmx_gp_e86hy8rn',\n",
    "'https://www.amazon.fr/Babycalin-Draps-Housse-Blanc-Gris/dp/B01N0NQ77B?ref_=Oct_d_obs_d_68991031&pd_rd_w=LRiAy&content-id=amzn1.sym.841e11e3-55d4-4422-a11a-1f6d3371ceeb&pf_rd_p=841e11e3-55d4-4422-a11a-1f6d3371ceeb&pf_rd_r=GFQ8K3ETDYTEVW2JKJW8&pd_rd_wg=51uL3&pd_rd_r=71e88ed7-df91-4b60-861d-8ecc0a65388b&pd_rd_i=B01N0NQ77B',\n",
    "'https://www.amazon.co.uk/England-Bunting-Decorations-Football-Restaurant/dp/B0B5G8RXL1/ref=sr_1_2_sspa?keywords=England&qid=1663176330&sr=8-2-spons&psc=1&spLa=ZW5jcnlwdGVkUXVhbGlmaWVyPUEzUDZPR1M1SkRWTUJLJmVuY3J5cHRlZElkPUEwMDIwMjY0UURCNVdOWURIM082JmVuY3J5cHRlZEFkSWQ9QTA1ODczNTczRVlKNDFCRFAxQUo1JndpZGdldE5hbWU9c3BfYXRmJmFjdGlvbj1jbGlja1JlZGlyZWN0JmRvTm90TG9nQ2xpY2s9dHJ1ZQ=='\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most of my app development to date has been confined to local devices. I wanted to develop a set of skills that would allow me to easily network any document-based app in the future. Network back-and-forth should be condensed to a bare minimum, and rollbacks and re-syncs should practically never happen. Merge should always be automatic, even for concurrent edits, and sync should be seamlessly integrated in real-time.\n"
     ]
    }
   ],
   "source": [
    "#Try with clean data\n",
    "\n",
    "article = wget.download(data_url[2])\n",
    "\n",
    "filename = \"file:///C:\\\\Users\\\\Qquentin\\\\Downloads\\\\\" + article\n",
    "\n",
    "data = textractor_model_paragraph(\"file:///C:\\\\Users\\\\Qquentin\\\\Downloads\\\\\" + article)\n",
    "\n",
    "data = [item for item in data if len(item)>100]\n",
    "\n",
    "text_summary = summary_model(\" \".join(data))\n",
    "\n",
    "print(text_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AssemblyAI Speech-to-Text API | Automatic Speech RecognitionChat with us, powered by LiveChat. We're loved by companies of all sizes — from startups to Fortune 500 companies. Transcription and Audio Intelligence - summarization, content moderation, topic detection, and more powered by cutting-edge AI models.\n"
     ]
    }
   ],
   "source": [
    "#From wget to request method and data clean/sorted\n",
    "\n",
    "#file needed to store text from request\n",
    "file_path = 'E:\\Projet\\Jots\\site_content.txt'\n",
    "\n",
    "#Request the content of a website\n",
    "header = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/39.0.2171.95 Safari/537.36'}\n",
    "r = requests.get(data_url[4], allow_redirects=True, headers=header)\n",
    "\n",
    "#Write the content of the request in a file\n",
    "fo = open(file_path, 'wb')\n",
    "fo.write(r.content)\n",
    "fo.close()\n",
    "\n",
    "#Extration of the text from the file\n",
    "data = textractor_model_paragraph('file:///' + file_path)\n",
    "\n",
    "#print(data)\n",
    "\n",
    "#Clean the data from low paragraph\n",
    "data = [item for item in data if len(item)>100]\n",
    "data = sorted(data, key=len, reverse = True)\n",
    "\n",
    "#Summarize the data\n",
    "text_summary = summary_model(\" \".join(data))\n",
    "\n",
    "print(text_summary)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calcul of the number of paragraph and sentence found in the website\n",
    "\n",
    "#file needed to store text from request\n",
    "file_path = 'E:\\Projet\\Jots\\site_content.txt'\n",
    "\n",
    "header = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/39.0.2171.95 Safari/537.36'}\n",
    "\n",
    "j=0\n",
    "\n",
    "for url in data_url:\n",
    "    j=j+1\n",
    "    #Request the content of a website\n",
    "    r = requests.get(url, allow_redirects=True, headers=header)\n",
    "\n",
    "    #Write the content of the request in a file\n",
    "    fo = open(file_path, 'wb')\n",
    "    fo.write(r.content)\n",
    "    fo.close()\n",
    "\n",
    "    #Extration of the text from the file\n",
    "    data = textractor_model_paragraph('file:///' + file_path)\n",
    "    data2 = textractor_model_sentence('file:///' + file_path)\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"%s %d %s %s\" % (\"Url number \",j, \" : \"  , url))\n",
    "    print(\"%s %s\" % (\"Paragraph number : \", len(data)))\n",
    "    print(\"%s %s\" % (\"Sentence number : \", len(data2)))\n",
    "    print(\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.lemonde.fr/pixels/article/2022/09/14/concurrence-google-echoue-a-faire-annuler-une-amende-record-devant-la-justice-europeenne_6141575_4408996.html\n",
      "--------------------------------------------------\n",
      "Actuality\n",
      "                                                  \n",
      "Summarize  3  :  Google devra bien payer une amende de 4,1 milliards d’euros à la justice européenne for non-respect of the concurrence Consulterle journal Navigation Le Monde - retour à la une Se connecter Se connecting S’abonner À la une nav_back_to_home En continu Actualités En ce moment Guerre en Ukraine Jean-Luc Godard Réforme des retraites Climat Reine Elizabeth II (1926 - 2022) Fin de vie Coronavirus and pandémie de Covid-19 Éducation Toute l’actualité en\n",
      "----------------------------------------------------------------------------------------------------\n",
      "https://www.leparisien.fr/faits-divers/incendie-en-gironde-des-centaines-de-personnes-evacuees-pres-dun-millier-de-pompiers-mobilises-14-09-2022-XDWAUFYCPNDYHHMG4AR25ODRII.php\n",
      "--------------------------------------------------\n",
      "Actuality\n",
      "                                                  \n",
      "Summarize  2  :  Incendie en Gironde : le feu ‘contenu mais fixé’, plus de 1000 personnes évacuées - Le Parisien S’abonner. 3 800 hectares of végétation  étééréréré déjà brûlé lundi du côté de Saumos.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "https://reflect.app/\n",
      "--------------------------------------------------\n",
      "Actuality\n",
      "                                                  \n",
      "Summarize  2  :  ReflectLoading...\n",
      "----------------------------------------------------------------------------------------------------\n",
      "https://apps.apple.com/us/app/reflect-guided-daily-journal/id1443541171\n",
      "--------------------------------------------------\n",
      "Shop\n",
      "                                                  \n",
      "Summarize  1  :  Reflect - guided daily journal on the App Store Global Nav Open Menu Global Nav Close Menu Apple Shopping Bag + Search apple. com Cancel Apple Store Mac iPad iPhone Watch AirPods TV & Home Only on Apple Accessories Support Shopping bag + Cancel App Store Preview Reflect -guided daily journal 4+ Self reflection journaling Ensparkle OOD Designed for iPad 4. 6 • 285 Ratings Free Offers In-App Purchases Screenshots iPad iPhone Description - \"When you do reflect it is really a chance to let out your feelings and not have to hide\"\n",
      "----------------------------------------------------------------------------------------------------\n",
      "https://www.assemblyai.com/?ref=ph_topic&utm_campaign=jun2022&utm_medium=cpc&utm_source=producthunt\n",
      "--------------------------------------------------\n",
      "Artificial intelligence\n",
      "                                                  \n",
      "Summarize  0  :  AssemblyAI process millions of audio files every day for hundreds of customers, including dozens of Fortune 500 enterprises. Built for developers, AssemblyAI provides comprehensive support to developers through our in-depth tutorials, detailed documentation, and changelog. Built-in-depth tutorial and comprehensive documentation. Trusted by 6,000+ businesses.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "https://stackoverflow.com/questions/65808445/electron-how-to-create-deep-linking-on-linux\n",
      "--------------------------------------------------\n",
      "Coding\n",
      "                                                  \n",
      "Summarize  0  :  Teams Electron - How to create deep-linking on Linux? How to kill a process running on particular port in Linux? Related 1749 How do I prompt for Yes/No/Cancel input in a Linux shell script? How do do I profile C++ code running on Linux ?\n",
      "----------------------------------------------------------------------------------------------------\n",
      "https://heyday.xyz/\n",
      "--------------------------------------------------\n",
      "Artificial intelligence\n",
      "                                                  \n",
      "Summarize  0  :  Heyday automatically saves pages you visit and resurfaces them alongside relevant results. It's loaded with incredibly useful content that makes life easier, smarter, and just downright enjoyable. Heyday is a great product for creators and knowledge workers alike. Read the news on TechCrunch. com.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "https://github.com/alex-shapiro/ditto\n",
      "--------------------------------------------------\n",
      "Coding\n",
      "                                                  \n",
      "Summarize  1  :  Ditto is a library for using CRDTs, or conflict-free replicated data types. It is licensed under either of Apache License, Version 2. 0 or MIT license at your option. Ditto does not include a networking layer. GitHub Skills Changelog Solutions By Size Enterprise Teams Compare all By Solution CI/CD & Automation DevOps DevSecOps Case Studies.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "http://archagon.net/blog/2018/03/24/data-laced-with-history/\n",
      "--------------------------------------------------\n",
      "Coding\n",
      "                                                  \n",
      "Summarize  3  :  Data Laced with History: Causal Trees & Operational CRDTs — Archagon Was Here Blog Archive About / Data Laced With History: causal trees & operationalCRDTs Mar 24, 2018 programming Hello! This article took a while to cobble together. If you find it useful, please consider leaving a donation via DonorBox or BuyMeACoffee.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "https://towardsdatascience.com/milvus-pinecone-vespa-weaviate-vald-gsi-what-unites-these-buzz-words-and-what-makes-each-9c65a3bd0696\n",
      "--------------------------------------------------\n",
      "Coding\n",
      "                                                  \n",
      "Summarize  1  :  This blog post makes an independent attempt at highlighting the commonalities and differences between 7 vector databases, each offering a commercial cloud support. Milvus, Pinecone, Vespa, Weaviate, Vald, GSI and Qdrant are included in the list.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "https://www.tutorialspoint.com/python/file_close.htm\n",
      "--------------------------------------------------\n",
      "Coding\n",
      "                                                  \n",
      "Summarize  2  :  Python file method close() closes the opened file. A closed file cannot be read or written any more. Python automatically closes a file when the reference object of a file is reassigned to another file. Calling close() more than once is allowed. Python Basic Tutorial Python - Home Python - Overview Python - Basic Syntax Python - Quick Guide Python - Tools/Utilities Python - Useful Resources Python - Discussion Python - Questions and Answers.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "https://www.theguardian.com/football/2022/sep/14/premier-league-to-honour-queen-with-silence-applause-and-national-anthem-managers-suits\n",
      "--------------------------------------------------\n",
      "Actuality\n",
      "                                                  \n",
      "Summarize  3  :  Premier League to honour Queen with silence, applause and national anthem. Minute’s applause after 70 minutes to mark length of reign. Managers told to consider wearing suits and leading team out. Big screens and LED perimeter boards will display tribute images to Her Majesty. Flags at the grounds will be flying at half-mast.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "https://www.amazon.fr/GIANTARM-Filament-1-75mm-Imprimante-Transparent/dp/B08LZ7L7L1/?_encoding=UTF8&pd_rd_w=mk0pF&content-id=amzn1.sym.09646d5d-e648-4ed9-8271-617e79ecf41a&pf_rd_p=09646d5d-e648-4ed9-8271-617e79ecf41a&pf_rd_r=JHAND8X5AFF59JR900TP&pd_rd_wg=vBmkt&pd_rd_r=a18f73ce-0909-40bd-b6aa-2f04fb130f59&ref_=pd_gw_bmx_gp_e86hy8rn\n",
      "--------------------------------------------------\n",
      "Shop\n",
      "                                                  \n",
      "Summarize  1  :  Saisissez les caractères que vous voyez dans cette image. Essayez une autre image Continuer les achats Conditions générales de vente Vos informations personnelles © 1996-2015, Amazon. com, Inc. ou ses filiales.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "https://www.amazon.fr/Babycalin-Draps-Housse-Blanc-Gris/dp/B01N0NQ77B?ref_=Oct_d_obs_d_68991031&pd_rd_w=LRiAy&content-id=amzn1.sym.841e11e3-55d4-4422-a11a-1f6d3371ceeb&pf_rd_p=841e11e3-55d4-4422-a11a-1f6d3371ceeb&pf_rd_r=GFQ8K3ETDYTEVW2JKJW8&pd_rd_wg=51uL3&pd_rd_r=71e88ed7-df91-4b60-861d-8ecc0a65388b&pd_rd_i=B01N0NQ77B\n",
      "--------------------------------------------------\n",
      "Shop\n",
      "                                                  \n",
      "Summarize  1  :  Saisissez les caractères que vous voyez dans cette image. Essayez une autre image Continuer les achats Conditions générales de vente Vos informations personnelles © 1996-2015, Amazon. com, Inc. ou ses filiales.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "https://www.amazon.co.uk/England-Bunting-Decorations-Football-Restaurant/dp/B0B5G8RXL1/ref=sr_1_2_sspa?keywords=England&qid=1663176330&sr=8-2-spons&psc=1&spLa=ZW5jcnlwdGVkUXVhbGlmaWVyPUEzUDZPR1M1SkRWTUJLJmVuY3J5cHRlZElkPUEwMDIwMjY0UURCNVdOWURIM082JmVuY3J5cHRlZEFkSWQ9QTA1ODczNTczRVlKNDFCRFAxQUo1JndpZGdldE5hbWU9c3BfYXRmJmFjdGlvbj1jbGlja1JlZGlyZWN0JmRvTm90TG9nQ2xpY2s9dHJ1ZQ==\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your max_length is set to 142, but you input_length is only 83. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=41)\n",
      "Your max_length is set to 142, but you input_length is only 83. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=41)\n",
      "Your max_length is set to 142, but you input_length is only 75. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=37)\n",
      "Your max_length is set to 142, but you input_length is only 75. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=37)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shop\n",
      "                                                  \n",
      "Summarize  1  :  Type the characters you see in this image: Try different image. Continue shopping Conditions of Use & Sale Privacy Notice © 1996-2015, Amazon. com, Inc. or its affiliates. For best results, please make sure your browser is accepting cookies. Amazon. co. uk\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#Try to find the relevant sentence in the text by comparing to the url information. Then summarize it. Then Label it.\n",
    "\n",
    "#data_url = ['https://elephas.app/?utm_campaign=r-languagetech ']\n",
    "\n",
    "for url in data_url:\n",
    "\n",
    "    #file needed to store text from request\n",
    "    file_path = 'E:\\Projet\\Jots\\site_content.txt'\n",
    "\n",
    "\n",
    "    #Request the content of a website\n",
    "    header = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/39.0.2171.95 Safari/537.36'}\n",
    "    r = requests.get(url, allow_redirects=True, headers=header)\n",
    "\n",
    "    #Write the content of the request in a file\n",
    "    fo = open(file_path, 'wb')\n",
    "    fo.write(r.content)\n",
    "    fo.close()\n",
    "\n",
    "    #Extration of the text from the file\n",
    "    data_site = textractor_model_sentence('file:///' + file_path)\n",
    "\n",
    "    #Sorted data to find bigger sentence\n",
    "    #data_site_sorted = sorted(data_site, key=len, reverse = True)\n",
    "\n",
    "    #Build of query from url\n",
    "    o = urlparse(url)\n",
    "    url_path = o.path.replace(\"/\",\" \").replace(\"-\",\" \").replace(\"html\",\"\").replace(\"htm\",\"\").replace(\"php\",\"\")\n",
    "    url_hostname = o.hostname.replace(\".\",\" \").replace(\"www\",\"\")\n",
    "\n",
    "    if len(url_path)>10:\n",
    "        query = url_path\n",
    "    else:\n",
    "        query = url_hostname + url_path\n",
    "\n",
    "    print(url)\n",
    "    #print(query)\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "    anwser = embeddings.similarity(query, data_site)\n",
    "\n",
    "    data_site_sorted_relevant=[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"]\n",
    "\n",
    "    for k in range(min(10,len(anwser))):\n",
    "        data_site_sorted_relevant[k]=data_site[anwser[k][0]]\n",
    "\n",
    "    #print(\"%-20s %s\" % (\"Distilbart\", summary_model(\". \".join(data_site_sorted_relevant))))\n",
    "    #print(\"%-20s %s\" % (\"Bart\", summary_model2(\". \".join(data_site_sorted_relevant))))\n",
    "    #print(\"-\" * 50)\n",
    "    #print(\" \" * 50)\n",
    "\n",
    "    text0=summary_model(\". \".join(data_site_sorted_relevant))\n",
    "    text1=summary_model2(\". \".join(data_site_sorted_relevant))\n",
    "\n",
    "    #Second sumarize\n",
    "    data_site = textractor_model('file:///' + file_path)\n",
    "    text2=summary_model(data_site)\n",
    "    text3=summary_model2(data_site)\n",
    "\n",
    "    #find better summary\n",
    "    data_text=[text0,text1,text2,text3]\n",
    "\n",
    "    text_summary = embeddings.similarity(query, data_text)\n",
    "\n",
    "    indice = text_summary[0][0]\n",
    "    text = data_text[indice]\n",
    "\n",
    "    # List of labels\n",
    "    tags = [\"Actuality\", \"Coding\", \"Shop\", \"Artificial intelligence\"]\n",
    "\n",
    "    print(tags[labels_model(text, tags)[0][0]])\n",
    "    print(\" \" * 50)\n",
    "    print(\"%s %d %s %s\" % (\"Summarize \", indice+1, \" : \",text))\n",
    "    print(\"-\" * 100)\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Comparison between different model and method\n",
    "\n",
    "#file needed to store text from request\n",
    "file_path = 'E:\\Projet\\Jots\\site_content.txt'\n",
    "\n",
    "#Request the content of a website\n",
    "header = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/39.0.2171.95 Safari/537.36'}\n",
    "\n",
    "for url in data_url:\n",
    "\n",
    "    print(\" \" * 100)\n",
    "    print(\"*\" * 100)\n",
    "    print(\"%s\" % url)\n",
    "    print(\"-\" * 100)\n",
    "\n",
    "    r = requests.get(url, allow_redirects=True, headers=header)\n",
    "\n",
    "    #Write the content of the request in a file\n",
    "    fo = open(file_path, 'wb')\n",
    "    fo.write(r.content)\n",
    "    fo.close()\n",
    "\n",
    "    text_summary = [[\"\",\"\"],[\"\",\"\"],[\"\",\"\"],[\"\",\"\"],[\"\",\"\"],[\"\",\"\"],[\"\",\"\"],[\"\",\"\"],[\"\",\"\"],[\"\",\"\"],[\"\",\"\"],[\"\",\"\"],[\"\",\"\"],[\"\",\"\"]] \n",
    "\n",
    "    for i in range(3):\n",
    "        \n",
    "        if i==0:\n",
    "            #Extration of the text from the file\n",
    "            data_site = textractor_model('file:///' + file_path)\n",
    "            text_summary[0][0] = \"Textractor distilbart :\"\n",
    "            text_summary[0][1] = summary_model(data_site)\n",
    "            text_summary[1][0] = \"Textractor bart :\"\n",
    "            text_summary[1][1] = summary_model2(data_site)\n",
    "\n",
    "        if i!=0:\n",
    "            \n",
    "            if i==1:\n",
    "                #Extration of the text from the file\n",
    "                data_site = textractor_model_paragraph('file:///' + file_path)\n",
    "                text_model = \"Paragraph\"\n",
    "            else:\n",
    "                #Extration of the text from the file\n",
    "                data_site = textractor_model_sentence('file:///' + file_path)\n",
    "                text_model = \"Sentence\"\n",
    "\n",
    "\n",
    "            text_summary[6*(i-1)+2][0] = text_model + \" distilbart :\"\n",
    "            text_summary[6*(i-1)+2][1] = summary_model(\" \".join(data_site))\n",
    "            text_summary[6*(i-1)+3][0] = text_model + \" bart :\"\n",
    "            text_summary[6*(i-1)+3][1] = summary_model2(\" \".join(data_site))\n",
    "\n",
    "            #Clean the data from low paragraph\n",
    "            data_site = [item for item in data_site if len(item)>100]\n",
    "\n",
    "            text_summary[6*(i-1)+4][0] = text_model + \" clean distilbart :\"\n",
    "            text_summary[6*(i-1)+4][1] = summary_model(\" \".join(data_site))\n",
    "            text_summary[6*(i-1)+5][0] = text_model + \" clean bart :\"\n",
    "            text_summary[6*(i-1)+5][1] = summary_model2(\" \".join(data_site))\n",
    "\n",
    "            #Sorted the data with big paragraph up\n",
    "            data_site = sorted(data_site, key=len, reverse = True)\n",
    "\n",
    "            text_summary[6*(i-1)+6][0] = text_model + \" clean sorted distilbart :\"\n",
    "            text_summary[6*(i-1)+6][1] = summary_model(\" \".join(data_site))\n",
    "            text_summary[6*(i-1)+7][0] = text_model + \" clean sorted bart :\"\n",
    "            text_summary[6*(i-1)+7][1] = summary_model2(\" \".join(data_site))\n",
    "\n",
    "\n",
    "for i in range(len(text_summary)):\n",
    "    print(\"\")\n",
    "    print(\"%s %s\" % (text_summary[i][0], text_summary[i][1]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Labels query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text                                                                        Label\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Dodgers lose again, give up 3 HRs in a loss to the Giants                   Baseball\n",
      "Giants 5 Cardinals 4 final in extra innings                                 Baseball\n",
      "Dodgers drop Game 2 against the Giants, 5-4                                 Baseball\n",
      "Flyers 4 Lightning 1 final. 45 saves for the Lightning.                     Hockey\n",
      "Slashing, penalty, 2 minute power play coming up                            Hockey\n",
      "What a stick save!                                                          Hockey\n",
      "Leads the NFL in sacks with 9.5                                             Football\n",
      "UCF 38 Temple 13                                                            Football\n",
      "With the 30 yard completion, down to the 10 yard line                       Football\n",
      "Drains the 3pt shot!!, 0:15 remaining in the game                           Basketball\n",
      "Intercepted! Drives down the court and shoots for the win                   Basketball\n",
      "Massive dunk!!! they are now up by 15 with 2 minutes to go                  Basketball\n"
     ]
    }
   ],
   "source": [
    "data = [\"Dodgers lose again, give up 3 HRs in a loss to the Giants\",\n",
    "        \"Giants 5 Cardinals 4 final in extra innings\",\n",
    "        \"Dodgers drop Game 2 against the Giants, 5-4\",\n",
    "        \"Flyers 4 Lightning 1 final. 45 saves for the Lightning.\",\n",
    "        \"Slashing, penalty, 2 minute power play coming up\",\n",
    "        \"What a stick save!\",\n",
    "        \"Leads the NFL in sacks with 9.5\",\n",
    "        \"UCF 38 Temple 13\",\n",
    "        \"With the 30 yard completion, down to the 10 yard line\",\n",
    "        \"Drains the 3pt shot!!, 0:15 remaining in the game\",\n",
    "        \"Intercepted! Drives down the court and shoots for the win\",\n",
    "        \"Massive dunk!!! they are now up by 15 with 2 minutes to go\"]\n",
    "\n",
    "# List of labels\n",
    "tags = [\"Baseball\", \"Football\", \"Hockey\", \"Basketball\"]\n",
    "\n",
    "print(\"%-75s %s\" % (\"Text\", \"Label\"))\n",
    "print(\"-\" * 100)\n",
    "\n",
    "for text in data:\n",
    "    print(\"%-75s %s\" % (text, tags[labels_model(text, tags)[0][0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text                                                                        Label\n",
      "----------------------------------------------------------------------------------------------------\n",
      "In 2021, Mem is the fastest way to capture, connect, and make use of information. Information\n",
      "Jots is an application at the crossing between note taking, journaling, time and task management. Journal\n",
      "Quentin like chocolate                                                      Personnal\n",
      "Cedric went to theatre on thurday                                           Event\n",
      "Cedric like coding app                                                      Professional\n",
      "Gift idea for Mel: t-shirt, bag                                             Personnal\n",
      "List Crazy AI application                                                   List\n",
      "Cave exploration session with Emeric, Gaetan and Annabelle on 23/09/22 at Bryant. Event\n"
     ]
    }
   ],
   "source": [
    "data = [\"In 2021, Mem is the fastest way to capture, connect, and make use of information.\",\n",
    "        \"Jots is an application at the crossing between note taking, journaling, time and task management.\",\n",
    "        \"Quentin like chocolate\",\n",
    "        \"Cedric went to theatre on thurday\",\n",
    "        \"Cedric like coding app\",\n",
    "        \"Gift idea for Mel: t-shirt, bag\",\n",
    "        \"List Crazy AI application\",\n",
    "        \"Cave exploration session with Emeric, Gaetan and Annabelle on 23/09/22 at Bryant.\"]\n",
    "\n",
    "# List of labels\n",
    "tags = [\"Event\", \"Information\", \"Journal\", \"Note\",\"Personnal\" ,\"Professional\", \"List\"]\n",
    "\n",
    "print(\"%-75s %s\" % (\"Text\", \"Label\"))\n",
    "print(\"-\" * 100)\n",
    "\n",
    "for text in data:\n",
    "    print(\"%-75s %s\" % (text, tags[labels_model(text, tags)[0][0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[(0, 0.30133727192878723), (3, 0.18833155930042267), (4, 0.18159928917884827), (1, 0.12484999001026154), (6, 0.10454705357551575), (2, 0.06393586844205856), (5, 0.03539896756410599)]]\n"
     ]
    }
   ],
   "source": [
    "data = [\"Crazy AI application\"]\n",
    "\n",
    "# List of labels\n",
    "tags = [\"Event\", \"Information\", \"Journal\", \"Note\",\"Personnal\" ,\"Professional\", \"List\"]\n",
    "\n",
    "print(labels_model(data, tags))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://github.com/alex-shapiro/ditto\n",
      " alex shapiro ditto\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nl = [[\"a\",\"b\"]]*10\\nb=\". \".join(l[0:10][1])\\n\\n\\nprint(l)\\nprint(b)'"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#text.split(\" \");\n",
    "\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "url=data_url[7]\n",
    "o = urlparse(url)\n",
    "url_path = o.path.replace(\"/\",\" \").replace(\"-\",\" \").replace(\"html\",\"\").replace(\"htm\",\"\").replace(\"php\",\"\")\n",
    "url_hostname = o.hostname.replace(\".\",\" \").replace(\"www\",\"\")\n",
    "\n",
    "if len(url_path)>10:\n",
    "    query = url_path\n",
    "else:\n",
    "    query = url_hostname + url_path\n",
    "\n",
    "print(url)\n",
    "print(query)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "l = [[\"a\",\"b\"]]*10\n",
    "b=\". \".join(l[0:10][1])\n",
    "\n",
    "\n",
    "print(l)\n",
    "print(b)\"\"\"\n",
    "\n",
    "\n",
    "#l = sorted(l, key=len, reverse = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Translate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Esta es una traducción de prueba al español'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translation = translate_model(\"This is a test translation into Spanish\", \"es\")\n",
    "translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Stable diffusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://huggingface.co/CompVis/stable-diffusion-v1-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import autocast\n",
    "from diffusers import StableDiffusionPipeline\n",
    "\n",
    "model_id = \"CompVis/stable-diffusion-v1-4\"\n",
    "device = \"cuda\"\n",
    "\n",
    "\n",
    "pipe = StableDiffusionPipeline.from_pretrained(model_id, use_auth_token='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')\n",
    "pipe = pipe.to(device)\n",
    "\n",
    "prompt = \"a photo of an astronaut riding a horse on mars\"\n",
    "with autocast(\"cuda\"):\n",
    "    image = pipe(prompt, guidance_scale=7.5).images[0]  \n",
    "    \n",
    "image.save(\"astronaut_rides_horse.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Mini DallE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from min_dalle import MinDalle\n",
    "\n",
    "Dalle_model = MinDalle(is_mega=False, is_verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_stream = Dalle_model.generate_image_stream(\n",
    "    text='Incendie en Gironde : le feu ‘contenu mais fixé’, plus de 1000 personnes évacuées - Le Parisien S’abonner. 3 800 hectares of végétation  étééréréré déjà brûlé lundi du côté de Saumos.',\n",
    "    seed=-1,\n",
    "    grid_size=3,\n",
    "    progressive_outputs=False,\n",
    "    is_seamless=False,\n",
    "    temperature=1,\n",
    "    top_k=256,\n",
    "    supercondition_factor=16,\n",
    "    is_verbose=False\n",
    ")\n",
    "\n",
    "for image in image_stream:\n",
    "    display(image)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f800a277f73fad4896a460eaa489683c53f96f0fdb097dbced45fa55364e6c2b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
